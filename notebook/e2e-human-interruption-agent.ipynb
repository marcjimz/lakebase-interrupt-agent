{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {
       "application/vnd.databricks.v1+cell": {
        "cellMetadata": {},
        "inputWidgets": {},
        "nuid": "a309b6d6-a7e7-49a6-929a-b7bde0778bc9",
        "showTitle": false,
        "tableResultSettingsMap": {},
        "title": ""
       }
      },
      "source": [
       "# \uD83E\uDD16 Human Interruption Agent Development\n",
       "\n",
       "Build a LangGraph agent with human-in-the-loop approval capabilities for high-risk operations on Databricks.\n",
       "\n",
       "**Tech Stack:** \n",
       "- \uD83C\uDFE2 **Databricks Foundation Models** - Pay-per-token LLM endpoints\n",
       "- \uD83D\uDDC4️ **Lakebase (Postgres)** - Persistent state management\n",
       "- \uD83D\uDD04 **LangGraph** - Stateful agent workflows with interruption points\n",
       "- \uD83D\uDCCA **MLflow** - Model tracking and deployment"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {
       "application/vnd.databricks.v1+cell": {
        "cellMetadata": {},
        "inputWidgets": {},
        "nuid": "c7b4c0c0-1755-414f-a2f4-d1790a0ba301",
        "showTitle": false,
        "tableResultSettingsMap": {},
        "title": ""
       }
      },
      "source": [
       "## \uD83D\uDCE6 Install Requirements\n",
       "\n",
       "Install all necessary packages for agent development and deployment."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
       "application/vnd.databricks.v1+cell": {
        "cellMetadata": {
         "byteLimit": 2048000,
         "rowLimit": 10000
        },
        "inputWidgets": {},
        "nuid": "06de45ef-00ab-46c7-8df1-4ab3a2f5bcbe",
        "showTitle": false,
        "tableResultSettingsMap": {},
        "title": ""
       }
      },
      "outputs": [
       {
        "output_type": "stream",
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
        ]
       }
      ],
      "source": [
       "# Install required packages from requirements.txt\n",
       "%pip install -q -r ../requirements.txt"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
       "application/vnd.databricks.v1+cell": {
        "cellMetadata": {
         "byteLimit": 2048000,
         "rowLimit": 10000
        },
        "inputWidgets": {},
        "nuid": "0522f58d-139b-439f-96e1-d372c2542715",
        "showTitle": false,
        "tableResultSettingsMap": {},
        "title": ""
       }
      },
      "outputs": [],
      "source": [
       "dbutils.library.restartPython()"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {
       "application/vnd.databricks.v1+cell": {
        "cellMetadata": {
         "byteLimit": 2048000,
         "rowLimit": 10000
        },
        "inputWidgets": {},
        "nuid": "e2c9cb5d-b2bb-4ae9-96db-04937609b40d",
        "showTitle": false,
        "tableResultSettingsMap": {},
        "title": ""
       }
      },
      "source": [
       "## ⚙️ Configuration & Setup\n",
       "\n",
       "Configure your Databricks environment and credentials. The widgets below allow you to customize:\n",
       "- Lakebase instance for persistence\n",
       "- Service principal credentials for authentication\n",
       "- Model serving endpoint selection\n",
       "- Unity Catalog location for functions and models"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
       "application/vnd.databricks.v1+cell": {
        "cellMetadata": {
         "byteLimit": 2048000,
         "rowLimit": 10000
        },
        "inputWidgets": {},
        "nuid": "402cf9d3-2e32-4512-8341-31d057f6c3ad",
        "showTitle": false,
        "tableResultSettingsMap": {},
        "title": ""
       }
      },
      "outputs": [],
      "source": [
       "# Import all required libraries\n",
       "import os\n",
       "import sys\n",
       "import pathlib\n",
       "import uuid\n",
       "import json\n",
       "import time\n",
       "from datetime import datetime\n",
       "from sqlalchemy import create_engine, text\n",
       "from databricks.sdk import WorkspaceClient\n",
       "import mlflow\n",
       "import mlflow.pyfunc\n",
       "from mlflow.models.resources import DatabricksServingEndpoint\n",
       "\n",
       "# Add src directory to Python path\n",
       "repo_root = pathlib.Path().absolute()\n",
       "src_path = repo_root / 'src'\n",
       "if str(src_path) not in sys.path:\n",
       "    sys.path.append(str(src_path))\n",
       "\n",
       "# Import helper modules first\n",
       "# from src.utils.helpers import read_requirements\n",
       "\n",
       "# Create configuration widgets\n",
       "dbutils.widgets.text(\"lakebase_instance\", \"agent-human-interaction\", \"Lakebase Instance Name\")\n",
       "dbutils.widgets.text(\"db_client_id\", \"<uuid>\", \"Databricks Client ID\") #make sure this is created\n",
       "dbutils.widgets.text(\"db_client_secret\", \"Secret\", \"Databricks Client Secret\") #make sure this is created\n",
       "dbutils.widgets.text(\"endpoint_name\", \"databricks-claude-3-7-sonnet\", \"Model Serving Endpoint\")\n",
       "dbutils.widgets.text(\"catalog_name\", \"_databricks_demos\", \"Databricks Catalog\")\n",
       "dbutils.widgets.text(\"schema_name\", \"sql_workshop\", \"Schema name\")\n",
       "\n",
       "# Get configuration from widgets\n",
       "LAKEBASE_INSTANCE = dbutils.widgets.get(\"lakebase_instance\")\n",
       "DATABRICKS_CLIENT_ID = dbutils.widgets.get(\"db_client_id\")\n",
       "DATABRICKS_CLIENT_SECRET = dbutils.widgets.get(\"db_client_secret\")\n",
       "ENDPOINT_NAME = dbutils.widgets.get(\"endpoint_name\")\n",
       "WORKSPACE_URL = dbutils.notebook.entry_point.getDbutils().notebook().getContext().browserHostName().get()\n",
       "CATALOG_NAME = dbutils.widgets.get(\"catalog_name\")\n",
       "SCHEMA_NAME = dbutils.widgets.get(\"schema_name\")\n",
       "\n",
       "# Set environment variables for AGENT initialization\n",
       "os.environ[\"ENDPOINT_NAME\"] = ENDPOINT_NAME\n",
       "os.environ[\"LAKEBASE_INSTANCE\"] = LAKEBASE_INSTANCE\n",
       "os.environ[\"LAKEBASE_USER\"] = DATABRICKS_CLIENT_ID\n",
       "os.environ[\"DATABRICKS_CLIENT_ID\"] = DATABRICKS_CLIENT_ID\n",
       "os.environ[\"DATABRICKS_CLIENT_SECRET\"] = DATABRICKS_CLIENT_SECRET\n",
       "os.environ[\"DATABRICKS_HOST\"] = f\"http://{WORKSPACE_URL}\"\n",
       "\n",
       "print(f\"✅ Environment variables set:\")\n",
       "print(f\"   LAKEBASE_INSTANCE: {LAKEBASE_INSTANCE}\")\n",
       "print(f\"   ENDPOINT_NAME: {ENDPOINT_NAME}\")\n",
       "print(f\"   CATALOG_NAME: {CATALOG_NAME}\")\n",
       "print(f\"   SCHEMA_NAME: {SCHEMA_NAME}\")\n",
       "print(f\"   DATABRICKS_CLIENT_ID: {DATABRICKS_CLIENT_ID}\")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
       "application/vnd.databricks.v1+cell": {
        "cellMetadata": {
         "byteLimit": 2048000,
         "implicitDf": true,
         "rowLimit": 10000
        },
        "inputWidgets": {},
        "nuid": "6b4df0a2-7e99-4c46-a889-e6ece37061ef",
        "showTitle": false,
        "tableResultSettingsMap": {},
        "title": ""
       }
      },
      "outputs": [],
      "source": [
       "spark.sql(f\"\"\"CREATE OR REPLACE FUNCTION {CATALOG_NAME}.{SCHEMA_NAME}.get_top_usage(\n",
       "  target_date DATE\n",
       ")\n",
       "RETURNS TABLE (\n",
       "  workspace_id BIGINT,\n",
       "  sku_name STRING,\n",
       "  usage_type STRING,\n",
       "  total_usage DOUBLE,\n",
       "  usage_unit STRING,\n",
       "  estimated_cost DOUBLE\n",
       ")\n",
       "LANGUAGE SQL\n",
       "COMMENT 'Returns top usage for a given day'\n",
       "RETURN\n",
       "  SELECT \n",
       "    u.workspace_id,\n",
       "    u.sku_name,\n",
       "    u.usage_type,\n",
       "    SUM(u.usage_quantity) as total_usage,\n",
       "    MAX(u.usage_unit) as usage_unit,\n",
       "    SUM(u.usage_quantity * COALESCE(p.pricing.default, 0)) as estimated_cost\n",
       "  FROM system.billing.usage u\n",
       "  LEFT JOIN system.billing.list_prices p\n",
       "    ON u.cloud = p.cloud\n",
       "    AND u.sku_name = p.sku_name\n",
       "    AND u.usage_start_time >= p.price_start_time\n",
       "    AND (p.price_end_time IS NULL OR u.usage_start_time < p.price_end_time)\n",
       "  WHERE \n",
       "    u.usage_date = target_date\n",
       "  GROUP BY \n",
       "    u.workspace_id,\n",
       "    u.sku_name,\n",
       "    u.usage_type\n",
       "  ORDER BY estimated_cost DESC\n",
       "  LIMIT 100;\n",
       "\"\"\")\n",
       "spark.sql(f\"GRANT EXECUTE ON FUNCTION {CATALOG_NAME}.{SCHEMA_NAME}.get_top_usage TO `{DATABRICKS_CLIENT_ID}`;\")\n",
       "spark.sql(f\"GRANT CREATE MODEL ON SCHEMA {CATALOG_NAME}.{SCHEMA_NAME} TO `{DATABRICKS_CLIENT_ID}`\")\n",
       "spark.sql(f\"GRANT CREATE TABLE ON SCHEMA {CATALOG_NAME}.{SCHEMA_NAME} TO `{DATABRICKS_CLIENT_ID}`\")\n",
       "spark.sql(f\"GRANT USE CATALOG ON CATALOG {CATALOG_NAME} TO `{DATABRICKS_CLIENT_ID}`\")\n",
       "spark.sql(f\"GRANT USE SCHEMA ON SCHEMA {CATALOG_NAME}.{SCHEMA_NAME} TO `{DATABRICKS_CLIENT_ID}`\")\n",
       "os.environ[\"UC_FUNCTIONS\"] = f\"{CATALOG_NAME}.{SCHEMA_NAME}.get_top_usage\""
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
       "application/vnd.databricks.v1+cell": {
        "cellMetadata": {
         "byteLimit": 2048000,
         "implicitDf": true,
         "rowLimit": 10000
        },
        "inputWidgets": {},
        "nuid": "a896625d-7411-490a-a523-c4fb8d74406e",
        "showTitle": false,
        "tableResultSettingsMap": {},
        "title": ""
       }
      },
      "outputs": [
       {
        "output_type": "display_data",
        "data": {
         "text/html": [
          "<style scoped>\n",
          "  .table-result-container {\n",
          "    max-height: 300px;\n",
          "    overflow: auto;\n",
          "  }\n",
          "  table, th, td {\n",
          "    border: 1px solid black;\n",
          "    border-collapse: collapse;\n",
          "  }\n",
          "  th, td {\n",
          "    padding: 5px;\n",
          "  }\n",
          "  th {\n",
          "    text-align: left;\n",
          "  }\n",
          "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>sku_name</th><th>usage_type</th><th>total_usage</th><th>usage_unit</th></tr></thead><tbody><tr><td>PREMIUM_SERVERLESS_REAL_TIME_INFERENCE_US_EAST_2</td><td>COMPUTE_TIME</td><td>6876.792172237659</td><td>DBU</td></tr><tr><td>PREMIUM_SERVERLESS_REAL_TIME_INFERENCE_AUSTRALIA_EAST</td><td>COMPUTE_TIME</td><td>3428.57142864</td><td>DBU</td></tr><tr><td>PREMIUM_SERVERLESS_REAL_TIME_INFERENCE_US_EAST</td><td>COMPUTE_TIME</td><td>3867.3599999999997</td><td>DBU</td></tr><tr><td>PREMIUM_SERVERLESS_REAL_TIME_INFERENCE_US_EAST</td><td>COMPUTE_TIME</td><td>3428.571456</td><td>DBU</td></tr><tr><td>PREMIUM_SERVERLESS_SQL_COMPUTE_US_WEST_2</td><td>COMPUTE_TIME</td><td>304.04372222222224</td><td>DBU</td></tr></tbody></table></div>"
         ]
        },
        "metadata": {
         "application/vnd.databricks.v1+output": {
          "addedWidgets": {},
          "aggData": [],
          "aggError": "",
          "aggOverflow": false,
          "aggSchema": [],
          "aggSeriesLimitReached": false,
          "aggType": "",
          "arguments": {},
          "columnCustomDisplayInfos": {},
          "data": [
           [
            "PREMIUM_SERVERLESS_REAL_TIME_INFERENCE_US_EAST_2",
            "COMPUTE_TIME",
            6876.792172237659,
            "DBU"
           ],
           [
            "PREMIUM_SERVERLESS_REAL_TIME_INFERENCE_AUSTRALIA_EAST",
            "COMPUTE_TIME",
            3428.57142864,
            "DBU"
           ],
           [
            "PREMIUM_SERVERLESS_REAL_TIME_INFERENCE_US_EAST",
            "COMPUTE_TIME",
            3867.3599999999997,
            "DBU"
           ],
           [
            "PREMIUM_SERVERLESS_REAL_TIME_INFERENCE_US_EAST",
            "COMPUTE_TIME",
            3428.571456,
            "DBU"
           ],
           [
            "PREMIUM_SERVERLESS_SQL_COMPUTE_US_WEST_2",
            "COMPUTE_TIME",
            304.04372222222224,
            "DBU"
           ]
          ],
          "datasetInfos": [],
          "dbfsResultPath": null,
          "isJsonSchema": true,
          "metadata": {},
          "overflow": false,
          "plotOptions": {
           "customPlotOptions": {},
           "displayType": "table",
           "pivotAggregation": null,
           "pivotColumns": null,
           "xColumns": null,
           "yColumns": null
          },
          "removedWidgets": [],
          "schema": [
           {
            "metadata": "{}",
            "name": "sku_name",
            "type": "\"string\""
           },
           {
            "metadata": "{}",
            "name": "usage_type",
            "type": "\"string\""
           },
           {
            "metadata": "{}",
            "name": "total_usage",
            "type": "\"double\""
           },
           {
            "metadata": "{}",
            "name": "usage_unit",
            "type": "\"string\""
           }
          ],
          "type": "table"
         }
        },
        "output_type": "display_data"
       }
      ],
      "source": [
       "test = spark.sql(f\"SELECT sku_name, usage_type, total_usage, usage_unit FROM {CATALOG_NAME}.{SCHEMA_NAME}.get_top_usage(CURRENT_DATE() - 1) LIMIT 5\")\n",
       "display(test)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {
       "application/vnd.databricks.v1+cell": {
        "cellMetadata": {
         "byteLimit": 2048000,
         "rowLimit": 10000
        },
        "inputWidgets": {},
        "nuid": "813f0681-35fc-43a6-9a5f-de20613fbf66",
        "showTitle": false,
        "tableResultSettingsMap": {},
        "title": ""
       }
      },
      "source": [
       "## \uD83D\uDDC4️ Lakebase (Postgres) Setup\n",
       "\n",
       "Initialize the Lakebase connection and create tables for conversation persistence. This enables the agent to maintain state across interruptions and resume conversations seamlessly.\n",
       "\n",
       "**Important:** Ensure your Databricks client ID has been assigned as a Postgres role with appropriate permissions on the Lakebase instance."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
       "application/vnd.databricks.v1+cell": {
        "cellMetadata": {
         "byteLimit": 2048000,
         "rowLimit": 10000
        },
        "inputWidgets": {},
        "nuid": "d45d940c-dc70-4bf6-933b-1b82d460b4b3",
        "showTitle": false,
        "tableResultSettingsMap": {},
        "title": ""
       }
      },
      "outputs": [],
      "source": [
       "#@TODO: Will want to move this to an OAuth token refresher for the agent, or using Postgres username/pwd\n",
       "from src.lakebase.database import LakebaseDatabase\n",
       "lb_conn = LakebaseDatabase(host=f\"http://{WORKSPACE_URL}\")\n",
       "conn_uri = lb_conn.initialize_connection(user=DATABRICKS_CLIENT_ID, instance_name=LAKEBASE_INSTANCE)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
       "application/vnd.databricks.v1+cell": {
        "cellMetadata": {
         "byteLimit": 2048000,
         "rowLimit": 10000
        },
        "inputWidgets": {},
        "nuid": "3a80ccc3-c252-4e7f-ae67-a56302b86a60",
        "showTitle": false,
        "tableResultSettingsMap": {},
        "title": ""
       }
      },
      "outputs": [],
      "source": [
       "from langgraph.checkpoint.postgres import PostgresSaver\n",
       "with PostgresSaver.from_conn_string(conn_uri) as checkpointer:\n",
       "    checkpointer.setup()"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {
       "application/vnd.databricks.v1+cell": {
        "cellMetadata": {
         "byteLimit": 2048000,
         "rowLimit": 10000
        },
        "inputWidgets": {},
        "nuid": "c9156791-1fc3-4e53-ba14-46cc3faee5c9",
        "showTitle": false,
        "tableResultSettingsMap": {},
        "title": ""
       }
      },
      "source": [
       "## \uD83D\uDE80 Initialize the Agent\n",
       "\n",
       "Import and initialize the human interruption agent. The agent will automatically configure itself using the environment variables set earlier."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
       "application/vnd.databricks.v1+cell": {
        "cellMetadata": {
         "byteLimit": 2048000,
         "rowLimit": 10000
        },
        "inputWidgets": {},
        "nuid": "8f69370e-911d-47e2-b8cf-cc0223c2c8cd",
        "showTitle": false,
        "tableResultSettingsMap": {},
        "title": ""
       }
      },
      "outputs": [],
      "source": [
       "# make sure you assign the databricks client id access databricks_superuser\n",
       "from src.agents.human_interruption_agent import AGENT"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {
       "application/vnd.databricks.v1+cell": {
        "cellMetadata": {
         "byteLimit": 2048000,
         "rowLimit": 10000
        },
        "inputWidgets": {},
        "nuid": "4b032a52-58b9-42e3-b709-a19e6727200f",
        "showTitle": false,
        "tableResultSettingsMap": {},
        "title": ""
       }
      },
      "source": [
       "## \uD83E\uDDEA Test Local Agent\n",
       "\n",
       "Let's test the agent locally before deploying to ensure it's working correctly."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
       "application/vnd.databricks.v1+cell": {
        "cellMetadata": {
         "byteLimit": 2048000,
         "rowLimit": 10000
        },
        "inputWidgets": {},
        "nuid": "d112bf90-4424-418b-937f-b8435f194388",
        "showTitle": false,
        "tableResultSettingsMap": {},
        "title": ""
       }
      },
      "outputs": [
       {
        "output_type": "stream",
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "✅ Using pre-initialized AGENT\nAgent type: LangGraphChatAgent\n"
        ]
       }
      ],
      "source": [
       "print(\"✅ Using pre-initialized AGENT\")\n",
       "print(f\"Agent type: {type(AGENT).__name__}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {
       "application/vnd.databricks.v1+cell": {
        "cellMetadata": {
         "byteLimit": 2048000,
         "rowLimit": 10000
        },
        "inputWidgets": {},
        "nuid": "7cc24f23-1aab-447a-9c68-b90c501f83c8",
        "showTitle": false,
        "tableResultSettingsMap": {},
        "title": ""
       }
      },
      "source": [
       "### \uD83D\uDD0D Query Agent Capabilities\n",
       "\n",
       "First, let's ask the agent about its available tools and functions. It should reference our Unity Catalog functions."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
       "application/vnd.databricks.v1+cell": {
        "cellMetadata": {
         "byteLimit": 2048000,
         "rowLimit": 10000
        },
        "inputWidgets": {},
        "nuid": "8b0b14f8-3742-4b8a-974e-e038a11b6a8f",
        "showTitle": false,
        "tableResultSettingsMap": {},
        "title": ""
       }
      },
      "outputs": [
       {
        "output_type": "stream",
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "Thread ID: e217c9a9-91b8-4833-9aa0-471218264e51\nAgent Response (agent type: <class 'src.agents.human_interruption_agent.LangGraphChatAgent'>, response type: <class 'mlflow.types.agent.ChatAgentResponse'>)\nI have access to a specific tool that allows me to retrieve data about usage statistics:\n\n- `marcin_databricks_demos__sql_workshop__get_top_usage`: This function returns top usage data for a specified date. It has one optional parameter:\n  - `target_date`: A date parameter that can be specified to get usage data for a particular day\n\nThis tool appears to be related to a Databricks SQL workshop and can provide information about top usage metrics for a given date.\n\nIs there something specific about usage data that you'd like me to help you with using this tool?\n"
        ]
       }
      ],
      "source": [
       "# Set the agent as the current model for this session\n",
       "mlflow.models.set_model(AGENT)\n",
       "\n",
       "response = AGENT.predict({\n",
       "    \"messages\": [\n",
       "        {\"role\": \"user\", \"content\": \"What capabilities do you have, specifically for tools and functions?\"}\n",
       "    ]\n",
       "})\n",
       "\n",
       "thread_id = response.custom_outputs.get('thread_id')\n",
       "print(f\"Thread ID: {thread_id}\")\n",
       "\n",
       "print(\"Agent Response (agent type: %s, response type: %s)\" % (type(AGENT), type(response)))\n",
       "print(response.messages[-1].content)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {
       "application/vnd.databricks.v1+cell": {
        "cellMetadata": {
         "byteLimit": 2048000,
         "rowLimit": 10000
        },
        "inputWidgets": {},
        "nuid": "2293c261-7cc2-4ed3-8650-92c518068d10",
        "showTitle": false,
        "tableResultSettingsMap": {},
        "title": ""
       }
      },
      "source": [
       "### \uD83D\uDCBE Test Conversation Persistence\n",
       "\n",
       "Verify that the agent remembers previous messages using the thread ID."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
       "application/vnd.databricks.v1+cell": {
        "cellMetadata": {
         "byteLimit": 2048000,
         "rowLimit": 10000
        },
        "inputWidgets": {},
        "nuid": "0bd8281e-f1a6-4dd4-a638-b373a1b8ef79",
        "showTitle": false,
        "tableResultSettingsMap": {},
        "title": ""
       }
      },
      "outputs": [
       {
        "output_type": "stream",
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "Agent Response (agent type: <class 'src.agents.human_interruption_agent.LangGraphChatAgent'>, response type: <class 'mlflow.types.agent.ChatAgentResponse'>)\nBased on the conversation history available to me, your previous question was: \"What capabilities do you have, specifically for tools and functions?\"\n\nIn that question, you were asking me about what tools and functions I have access to, and I responded by explaining that I have access to the `marcin_databricks_demos__sql_workshop__get_top_usage` function which can retrieve top usage data for a specified date.\n"
        ]
       }
      ],
      "source": [
       "time.sleep(2)\n",
       "followup_response = AGENT.predict(\n",
       "    messages=[\n",
       "        {\"role\": \"user\", \"content\": \"What was my previous question?\"}\n",
       "    ],\n",
       "    custom_inputs={\"thread_id\": thread_id}  # Pass the thread_id here\n",
       ")\n",
       "thread_id = followup_response.custom_outputs.get('thread_id')\n",
       "print(\"Agent Response (agent type: %s, response type: %s)\" % (type(AGENT), type(followup_response)))\n",
       "print(followup_response.messages[-1].content)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {
       "application/vnd.databricks.v1+cell": {
        "cellMetadata": {
         "byteLimit": 2048000,
         "rowLimit": 10000
        },
        "inputWidgets": {},
        "nuid": "ffb1880c-921f-407a-a352-1a98951fcad4",
        "showTitle": false,
        "tableResultSettingsMap": {},
        "title": ""
       }
      },
      "source": [
       "### ✅ Double-Check Memory\n",
       "\n",
       "Ensure persistence is working correctly with another follow-up."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
       "application/vnd.databricks.v1+cell": {
        "cellMetadata": {
         "byteLimit": 2048000,
         "rowLimit": 10000
        },
        "inputWidgets": {},
        "nuid": "5078bb7d-600f-488f-8871-8d39604404fe",
        "showTitle": false,
        "tableResultSettingsMap": {},
        "title": ""
       }
      },
      "outputs": [
       {
        "output_type": "stream",
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "Agent Response (agent type: <class 'src.agents.human_interruption_agent.LangGraphChatAgent'>, response type: <class 'mlflow.types.agent.ChatAgentResponse'>)\nBased on the conversation history available to me, your most recent question was: \"What was my previous question?\"\n\nIn response to that, I informed you that your previous question had been \"What capabilities do you have, specifically for tools and functions?\"\n"
        ]
       }
      ],
      "source": [
       "time.sleep(5) #Sleep to allow for persistence of previous query to occur.\n",
       "followup_response2 = AGENT.predict(\n",
       "    messages=[\n",
       "        {\"role\": \"user\", \"content\": \"What was my most recent question?\"}\n",
       "    ],\n",
       "    custom_inputs={\"thread_id\": thread_id}  # Pass the thread_id here\n",
       ")\n",
       "thread_id = followup_response2.custom_outputs.get('thread_id')\n",
       "print(\"Agent Response (agent type: %s, response type: %s)\" % (type(AGENT), type(followup_response)))\n",
       "print(followup_response2.messages[-1].content)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {
       "application/vnd.databricks.v1+cell": {
        "cellMetadata": {
         "byteLimit": 2048000,
         "rowLimit": 10000
        },
        "inputWidgets": {},
        "nuid": "9c4b8803-f1e6-4536-842a-a13dde3784f2",
        "showTitle": false,
        "tableResultSettingsMap": {},
        "title": ""
       }
      },
      "source": [
       "### \uD83D\uDEE0️ Test Unity Catalog Function Usage\n",
       "\n",
       "Trigger the agent to use our custom UC function - this should prompt for approval."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
       "application/vnd.databricks.v1+cell": {
        "cellMetadata": {
         "byteLimit": 2048000,
         "rowLimit": 10000
        },
        "inputWidgets": {},
        "nuid": "52e33605-4085-4500-b678-8a4ebc7db974",
        "showTitle": false,
        "tableResultSettingsMap": {},
        "title": ""
       }
      },
      "outputs": [
       {
        "output_type": "stream",
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "Agent Response (agent type: <class 'src.agents.human_interruption_agent.LangGraphChatAgent'>, response type: <class 'mlflow.types.agent.ChatAgentResponse'>)\n\uD83D\uDCCB **Tool Approval Required**\n\nI'm ready to execute the following tool:\n• Function: `marcin_databricks_demos__sql_workshop__get_top_usage`\n• Arguments: `{\"target_date\": \"2025-09-17\"}`\n\nPlease approve this action to continue, or provide alternative instructions.\n"
        ]
       }
      ],
      "source": [
       "time.sleep(5)\n",
       "tool_response = AGENT.predict(\n",
       "    messages=[\n",
       "        {\"role\": \"user\", \"content\": \"Can you get me the top usage for 2025-09-17 on the platform?\"}\n",
       "    ],\n",
       "    custom_inputs={\"thread_id\": thread_id}\n",
       ")\n",
       "thread_id = tool_response.custom_outputs.get('thread_id')\n",
       "print(\"Agent Response (agent type: %s, response type: %s)\" % (type(AGENT), type(tool_response)))\n",
       "print(tool_response.messages[-1].content)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {
       "application/vnd.databricks.v1+cell": {
        "cellMetadata": {
         "byteLimit": 2048000,
         "rowLimit": 10000
        },
        "inputWidgets": {},
        "nuid": "5d0c96a3-acaf-4425-9895-8b1c2941df9d",
        "showTitle": false,
        "tableResultSettingsMap": {},
        "title": ""
       }
      },
      "source": [
       "### ✅ Approve and Resume\n",
       "\n",
       "The agent has paused for approval. Let's approve the tool execution and see the results."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
       "application/vnd.databricks.v1+cell": {
        "cellMetadata": {
         "byteLimit": 2048000,
         "rowLimit": 10000
        },
        "inputWidgets": {},
        "nuid": "5f5d84d9-ea20-4510-840f-b3dbe6bbc6a2",
        "showTitle": false,
        "tableResultSettingsMap": {},
        "title": ""
       }
      },
      "outputs": [
       {
        "output_type": "stream",
        "name": "stderr",
        "output_type": "stream",
        "text": [
         "/local_disk0/.ephemeral_nfs/envs/pythonEnv-47310911-28a1-4466-a7c3-0067ecf417c5/lib/python3.10/site-packages/unitycatalog/ai/core/databricks.py:600: UserWarning: The following parameters do not have descriptions: target_date for the function marcin_databricks_demos.sql_workshop.get_top_usage. Using Unity Catalog functions that do not have parameter descriptions limits the functionality for an LLM to understand how to call your function. To improve tool calling accuracy, provide verbose parameter descriptions that fully explain what the expected usage of the function arguments are.\n  check_function_info(function_info)\n"
        ]
       },
       {
        "output_type": "stream",
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "Resume Response:\nBased on the data retrieved for September 17, 2025, here are the top usage statistics:\n\nThe highest usage for that day is from workspace ID 1720970340056130 using PREMIUM_SERVERLESS_REAL_TIME_INFERENCE_US_EAST_2 with a total usage of 6,876.79 DBUs (Databricks Units) and an estimated cost of $481.38.\n\nOther notable high usage entries include:\n- Workspace 1595657218862477: 3,428.57 DBUs ($301.71) for PREMIUM_SERVERLESS_REAL_TIME_INFERENCE_AUSTRALIA_EAST\n- Workspace 1756146239551418: 3,867.36 DBUs ($270.72) for PREMIUM_SERVERLESS_REAL_TIME_INFERENCE_US_EAST\n- Workspace 658946740795418: 3,428.57 DBUs ($240.00) for PREMIUM_SERVERLESS_REAL_TIME_INFERENCE_US_EAST\n\nThe data shows that serverless real-time inference services across different regions are the highest usage categories, followed by SQL compute and all-purpose compute services.\n\nWould you like me to provide any specific analysis of this usage data?\nInterrupted: False\n"
        ]
       }
      ],
      "source": [
       "time.sleep(5)\n",
       "resume_response = AGENT.resume(\n",
       "    command_value=\"approved\",  # or just None for default approval\n",
       "    thread_id=thread_id\n",
       ")\n",
       "\n",
       "print(\"Resume Response:\")\n",
       "print(resume_response.messages[-1].content)\n",
       "print(f\"Interrupted: {resume_response.custom_outputs.get('is_interrupted')}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {
       "application/vnd.databricks.v1+cell": {
        "cellMetadata": {
         "byteLimit": 2048000,
         "rowLimit": 10000
        },
        "inputWidgets": {},
        "nuid": "188550db-c0a4-4923-b4bb-3031b1ac0c57",
        "showTitle": false,
        "tableResultSettingsMap": {},
        "title": ""
       }
      },
      "source": [
       "## \uD83D\uDCDD Register Agent with MLflow\n",
       "\n",
       "Register the agent to MLflow for tracking and deployment. The agent includes all necessary dependencies and configuration.\n",
       "\n",
       "**Key Points:**\n",
       "- Agent must call `mlflow.models.set_model()` for deployment compatibility\n",
       "- Dependencies are bundled via `code_paths` parameter\n",
       "- Resources include the Databricks serving endpoint configuration"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
       "application/vnd.databricks.v1+cell": {
        "cellMetadata": {
         "byteLimit": 2048000,
         "rowLimit": 10000
        },
        "inputWidgets": {},
        "nuid": "b0b8099a-aebe-43c9-bd09-06a51531b534",
        "showTitle": false,
        "tableResultSettingsMap": {},
        "title": ""
       }
      },
      "outputs": [
       {
        "output_type": "stream",
        "name": "stderr",
        "output_type": "stream",
        "text": [
         "\uD83D\uDD17 View Logged Model at: https://adb-2482403303441070.10.azuredatabricks.net/ml/experiments/153332696905207/models/m-8c19e03a0a124f2c9fefe901630f4699?o=2482403303441070\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-47310911-28a1-4466-a7c3-0067ecf417c5/lib/python3.10/site-packages/databricks/connect/session.py:454: UserWarning: Ignoring the default notebook Spark session and creating a new Spark Connect session. To use the default notebook Spark session, use DatabricksSession.builder.getOrCreate() with no additional parameters.\n  warnings.warn(new_notebook_session_msg)\n2025/09/18 03:25:29 INFO mlflow.pyfunc: Predicting on input example to validate output\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-47310911-28a1-4466-a7c3-0067ecf417c5/lib/python3.10/site-packages/databricks/connect/session.py:454: UserWarning: Ignoring the default notebook Spark session and creating a new Spark Connect session. To use the default notebook Spark session, use DatabricksSession.builder.getOrCreate() with no additional parameters.\n  warnings.warn(new_notebook_session_msg)\n2025/09/18 03:25:37 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_CLIENT_ID, DATABRICKS_CLIENT_SECRET, DATABRICKS_HOST]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n"
        ]
       },
       {
        "output_type": "stream",
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "✅ Agent logged to MLflow with Unity Catalog\n   Model URI: models:/m-8c19e03a0a124f2c9fefe901630f4699\n   Artifact Path: dbfs:/databricks/mlflow-tracking/153332696905207/logged_models/m-8c19e03a0a124f2c9fefe901630f4699/artifacts\n   Registry URI: databricks-uc\n   Resources: [<mlflow.models.resources.DatabricksServingEndpoint object at 0x7f9477e22b30>]\n   Agent Config: {'endpoint_name': 'databricks-claude-3-7-sonnet', 'temperature': 0.1, 'max_tokens': 1000}\n"
        ]
       }
      ],
      "source": [
       "# Configure MLflow 3 with Unity Catalog\n",
       "agent_name = \"human-interruption-agent\"\n",
       "mlflow.set_experiment(f\"/Shared/{agent_name}\")\n",
       "mlflow.set_registry_uri('databricks-uc')\n",
       "\n",
       "# Define agent_path variable properly\n",
       "agent_path = \"../src/agents/human_interruption_agent.py\"\n",
       "\n",
       "# Create agent configuration following the triager pattern\n",
       "agent_config = {\n",
       "    \"endpoint_name\": ENDPOINT_NAME,\n",
       "    \"temperature\": 0.1,\n",
       "    \"max_tokens\": 1000,\n",
       "}\n",
       "\n",
       "# Create resources list with DatabricksServingEndpoint\n",
       "resources = [\n",
       "    DatabricksServingEndpoint(endpoint_name=agent_config.get(\"endpoint_name\"))\n",
       "] if agent_config.get(\"endpoint_name\") else []\n",
       "\n",
       "# Define input example\n",
       "input_example = {\n",
       "    \"messages\": [\n",
       "        {\"role\": \"user\", \"content\": \"What capabilities do you have, specifically for tools and functions?\"}\n",
       "    ]\n",
       "}\n",
       "\n",
       "# Read requirements using the helper function\n",
       "with open('../requirements.txt', 'r') as file:\n",
       "    requirements=[x for x in file.read().splitlines() if len(x) > 0 and x[0] != '#']\n",
       "\n",
       "# Log the agent as an MLflow model WITHOUT mlflow.start_run()\n",
       "# This follows the exact pattern from dbx-agent-triager\n",
       "model_info = mlflow.pyfunc.log_model(\n",
       "    name=agent_name,\n",
       "    python_model=agent_path,\n",
       "    model_config=agent_config,\n",
       "    resources=resources,\n",
       "    input_example=input_example,\n",
       "    pip_requirements=requirements,\n",
       "    code_paths=[\"../src\"]\n",
       ")\n",
       "\n",
       "print(f\"✅ Agent logged to MLflow with Unity Catalog\")\n",
       "print(f\"   Model URI: {model_info.model_uri}\")\n",
       "print(f\"   Artifact Path: {model_info.artifact_path}\")\n",
       "print(f\"   Registry URI: {mlflow.get_registry_uri()}\")\n",
       "print(f\"   Resources: {resources}\")\n",
       "print(f\"   Agent Config: {agent_config}\")\n",
       "\n",
       "# Store model info for later use\n",
       "MODEL_URI = model_info.model_uri"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {
       "application/vnd.databricks.v1+cell": {
        "cellMetadata": {
         "byteLimit": 2048000,
         "rowLimit": 10000
        },
        "inputWidgets": {},
        "nuid": "b012e4ce-02a5-458a-8087-352acd2af21a",
        "showTitle": false,
        "tableResultSettingsMap": {},
        "title": ""
       }
      },
      "source": [
       "### \uD83D\uDD0D Verify Model Registration\n",
       "\n",
       "Quick sanity check to ensure the model deserializes correctly from MLflow."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
       "application/vnd.databricks.v1+cell": {
        "cellMetadata": {
         "byteLimit": 2048000,
         "rowLimit": 10000
        },
        "inputWidgets": {},
        "nuid": "3d264519-e32e-48ee-a70e-ae3c7af8eaf7",
        "showTitle": false,
        "tableResultSettingsMap": {},
        "title": ""
       }
      },
      "outputs": [
       {
        "output_type": "display_data",
        "data": {
         "application/vnd.jupyter.widget-view+json": {
          "model_id": "0d79f66d79a14b0787531cb9b84ae62b",
          "version_major": 2,
          "version_minor": 0
         },
         "text/plain": [
          "Downloading artifacts:   0%|          | 0/17 [00:00<?, ?it/s]"
         ]
        },
        "metadata": {},
        "output_type": "display_data"
       },
       {
        "output_type": "stream",
        "name": "stderr",
        "output_type": "stream",
        "text": [
         "/local_disk0/.ephemeral_nfs/envs/pythonEnv-47310911-28a1-4466-a7c3-0067ecf417c5/lib/python3.10/site-packages/databricks/connect/session.py:454: UserWarning: Ignoring the default notebook Spark session and creating a new Spark Connect session. To use the default notebook Spark session, use DatabricksSession.builder.getOrCreate() with no additional parameters.\n  warnings.warn(new_notebook_session_msg)\n"
        ]
       },
       {
        "output_type": "execute_result",
        "data": {
         "text/plain": [
          "{'messages': [{'role': 'user',\n",
          "   'content': 'What capabilities do you have, specifically for tools and functions?',\n",
          "   'id': '599434af-e674-439b-85c2-dfd1ff793f85'},\n",
          "  {'role': 'assistant',\n",
          "   'content': 'I have access to a specific tool that allows me to retrieve data about usage patterns:\\n\\n- `marcin_databricks_demos__sql_workshop__get_top_usage`: This function returns top usage data for a specified date. It has one optional parameter called \"target_date\" which can be provided as a date string.\\n\\nThis tool appears to be related to a SQL workshop in Databricks and can help analyze usage patterns for a given day. If you\\'d like to use this tool, I can help you retrieve the data by executing the function with your specified date.\\n\\nIs there a particular date you\\'d like to analyze the top usage for?',\n",
          "   'id': 'run--1c4f7659-d16b-4d81-848b-e8ff199ba546-0'}],\n",
          " 'custom_outputs': {'thread_id': '48669a3c-01bc-42a3-a8d1-c3c5aa7991b4',\n",
          "  'is_interrupted': False,\n",
          "  'interrupt_data': None,\n",
          "  'requires_approval': False,\n",
          "  'pending_tool_calls': None,\n",
          "  'next_action': 'complete'}}"
         ]
        },
        "execution_count": 42,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": [
       "os.environ['MLFLOW_ARTIFACT_UPLOAD_DOWNLOAD_TIMEOUT'] = '600'  # Timeout in seconds\n",
       "loaded_model = mlflow.pyfunc.load_model(MODEL_URI)\n",
       "\n",
       "# Run prediction on input_example\n",
       "predictions = loaded_model.predict(input_example)\n",
       "\n",
       "# Display the predictions\n",
       "predictions"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {
       "application/vnd.databricks.v1+cell": {
        "cellMetadata": {
         "byteLimit": 2048000,
         "rowLimit": 10000
        },
        "inputWidgets": {},
        "nuid": "184997fe-46ef-4e63-816c-a09eb991c5d8",
        "showTitle": false,
        "tableResultSettingsMap": {},
        "title": ""
       }
      },
      "source": [
       "## \uD83D\uDCCA Evaluations\n",
       "\n",
       "Future section for MLflow evaluation sets with tool usage metrics."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
       "application/vnd.databricks.v1+cell": {
        "cellMetadata": {
         "byteLimit": 2048000,
         "rowLimit": 10000
        },
        "inputWidgets": {},
        "nuid": "dd6184cc-b158-4b97-ad75-9f37d481b1b3",
        "showTitle": false,
        "tableResultSettingsMap": {},
        "title": ""
       }
      },
      "outputs": [],
      "source": [
       "#@TODO, include evaluation set with MLflow for tool usage."
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {
       "application/vnd.databricks.v1+cell": {
        "cellMetadata": {
         "byteLimit": 2048000,
         "rowLimit": 10000
        },
        "inputWidgets": {},
        "nuid": "bb8157df-7c7b-44d2-a730-c94da38fd4c1",
        "showTitle": false,
        "tableResultSettingsMap": {},
        "title": ""
       }
      },
      "source": [
       "## \uD83C\uDFAF Register to Unity Catalog\n",
       "\n",
       "Register the model in Unity Catalog for centralized management and versioning."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
       "application/vnd.databricks.v1+cell": {
        "cellMetadata": {
         "byteLimit": 2048000,
         "rowLimit": 10000
        },
        "inputWidgets": {},
        "nuid": "ef63698e-bbed-4368-acac-1a1059130c11",
        "showTitle": false,
        "tableResultSettingsMap": {},
        "title": ""
       }
      },
      "outputs": [
       {
        "output_type": "stream",
        "name": "stderr",
        "output_type": "stream",
        "text": [
         "Registered model 'marcin_databricks_demos.sql_workshop.human-interruption-agent' already exists. Creating a new version of this model...\n2025/09/18 03:25:46 WARNING mlflow.store._unity_catalog.registry.rest_store: Unable to fetch model version's source run (with ID ) from tracking server. The source run may be deleted or inaccessible to the current user. No run link will be recorded for the model version.\n2025/09/18 03:25:46 WARNING mlflow.store._unity_catalog.registry.rest_store: Unable to get model version source run's workspace ID from request headers. No run link will be recorded for the model version\n"
        ]
       },
       {
        "output_type": "display_data",
        "data": {
         "application/vnd.jupyter.widget-view+json": {
          "model_id": "6bb87fec791240b0bf787f8db2bc5cee",
          "version_major": 2,
          "version_minor": 0
         },
         "text/plain": [
          "Downloading artifacts:   0%|          | 0/17 [00:00<?, ?it/s]"
         ]
        },
        "metadata": {},
        "output_type": "display_data"
       },
       {
        "output_type": "display_data",
        "data": {
         "application/vnd.jupyter.widget-view+json": {
          "model_id": "a209a82d93d74468b6370753ef71a750",
          "version_major": 2,
          "version_minor": 0
         },
         "text/plain": [
          "Uploading artifacts:   0%|          | 0/18 [00:00<?, ?it/s]"
         ]
        },
        "metadata": {},
        "output_type": "display_data"
       },
       {
        "output_type": "stream",
        "name": "stderr",
        "output_type": "stream",
        "text": [
         "\uD83D\uDD17 Created version '9' of model 'marcin_databricks_demos.sql_workshop.human-interruption-agent': https://adb-2482403303441070.10.azuredatabricks.net/explore/data/models/marcin_databricks_demos/sql_workshop/human-interruption-agent/version/9?o=2482403303441070\n"
        ]
       }
      ],
      "source": [
       "# Unity Catalog location\n",
       "uc_model_fqn = f\"{CATALOG_NAME}.{SCHEMA_NAME}.{agent_name}\"\n",
       "\n",
       "# Register the model to the Unity Catalog\n",
       "uc_registered_model_info = mlflow.register_model(model_uri=model_info.model_uri, name=uc_model_fqn)\n",
       "\n",
       "import mlflow\n",
       "from mlflow import MlflowClient\n",
       "\n",
       "# Initialize the MLflow client\n",
       "client = MlflowClient()\n",
       "\n",
       "# Set the alias for the registered model\n",
       "client.set_registered_model_alias(\n",
       "    name=uc_model_fqn,\n",
       "    alias=\"newest\",\n",
       "    version=uc_registered_model_info.version\n",
       ")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {
       "application/vnd.databricks.v1+cell": {
        "cellMetadata": {
         "byteLimit": 2048000,
         "rowLimit": 10000
        },
        "inputWidgets": {},
        "nuid": "c5d8bb01-04b7-4f22-8f9b-bc161e28f860",
        "showTitle": false,
        "tableResultSettingsMap": {},
        "title": ""
       }
      },
      "source": [
       "### \uD83D\uDCE6 Load from Unity Catalog\n",
       "\n",
       "Verify we can load the model from UC using the alias."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
       "application/vnd.databricks.v1+cell": {
        "cellMetadata": {
         "byteLimit": 2048000,
         "rowLimit": 10000
        },
        "inputWidgets": {},
        "nuid": "6f40019b-1164-4cff-a10b-68481bce91ad",
        "showTitle": false,
        "tableResultSettingsMap": {},
        "title": ""
       }
      },
      "outputs": [
       {
        "output_type": "display_data",
        "data": {
         "application/vnd.jupyter.widget-view+json": {
          "model_id": "2ee7bd558666459abc6906ad10fda650",
          "version_major": 2,
          "version_minor": 0
         },
         "text/plain": [
          "Downloading artifacts:   0%|          | 0/18 [00:00<?, ?it/s]"
         ]
        },
        "metadata": {},
        "output_type": "display_data"
       },
       {
        "output_type": "stream",
        "name": "stderr",
        "output_type": "stream",
        "text": [
         "/local_disk0/.ephemeral_nfs/envs/pythonEnv-47310911-28a1-4466-a7c3-0067ecf417c5/lib/python3.10/site-packages/databricks/connect/session.py:454: UserWarning: Ignoring the default notebook Spark session and creating a new Spark Connect session. To use the default notebook Spark session, use DatabricksSession.builder.getOrCreate() with no additional parameters.\n  warnings.warn(new_notebook_session_msg)\n"
        ]
       },
       {
        "output_type": "execute_result",
        "data": {
         "text/plain": [
          "{'messages': [{'role': 'user',\n",
          "   'content': 'What capabilities do you have, specifically for tools and functions?',\n",
          "   'id': 'e2ecbf73-615d-4150-96a3-1b9fc365b87c'},\n",
          "  {'role': 'assistant',\n",
          "   'content': \"I have access to a specific tool that allows me to retrieve top usage data for a given day from what appears to be a Databricks SQL workshop environment. The function is called `marcin_databricks_demos__sql_workshop__get_top_usage` and it takes an optional parameter called `target_date`.\\n\\nThis function likely returns usage metrics or statistics for the specified date, which could include information about SQL queries, resource consumption, or user activity within a Databricks environment.\\n\\nIf you'd like me to use this tool to retrieve usage data for a specific date, I can do that for you. You would just need to specify which date you're interested in, and I'll prepare the function call for your approval before executing it.\",\n",
          "   'id': 'run--fb66e09c-4f6e-4644-a01c-2be99ed1ec43-0'}],\n",
          " 'custom_outputs': {'thread_id': '710bf739-971d-4c69-8d6e-52902f5f316d',\n",
          "  'is_interrupted': False,\n",
          "  'interrupt_data': None,\n",
          "  'requires_approval': False,\n",
          "  'pending_tool_calls': None,\n",
          "  'next_action': 'complete'}}"
         ]
        },
        "execution_count": 45,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": [
       "import mlflow\n",
       "\n",
       "#@TODO: Implement MLflow tracing and MLFlow UI\n",
       "#uc_model_fqn = f\"databricks_agent.core.agent_builder\"\n",
       "model_uri = f\"models:/{uc_model_fqn}@newest\"\n",
       "loaded_model = mlflow.pyfunc.load_model(model_uri)\n",
       "loaded_model.predict(input_example)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {
       "application/vnd.databricks.v1+cell": {
        "cellMetadata": {
         "byteLimit": 2048000,
         "rowLimit": 10000
        },
        "inputWidgets": {},
        "nuid": "761faccc-52f6-491d-ae42-e2e4f309db0c",
        "showTitle": false,
        "tableResultSettingsMap": {},
        "title": ""
       }
      },
      "source": [
       "## \uD83D\uDE80 Deploy Agent to Production\n",
       "\n",
       "Deploy the agent as a Model Serving endpoint for production use. This creates a REST API and Review App interface."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
       "application/vnd.databricks.v1+cell": {
        "cellMetadata": {
         "byteLimit": 2048000,
         "rowLimit": 10000
        },
        "inputWidgets": {},
        "nuid": "64a9666f-346f-4851-a982-fb07067f9fcb",
        "showTitle": false,
        "tableResultSettingsMap": {},
        "title": ""
       }
      },
      "outputs": [],
      "source": [
       "from mlflow.utils import databricks_utils as du\n",
       "from mlflow.models.resources import DatabricksServingEndpoint, DatabricksVectorSearchIndex\n",
       "\n",
       "def parse_deployment_info(deployment_info):\n",
       "  browser_url = du.get_browser_hostname()\n",
       "  message = f\"\"\"Deployment of {deployment_info.model_name} version {deployment_info.model_version} initiated.  This can take up to 15 minutes and the Review App & REST API will not work until this deployment finishes. \n",
       "\n",
       "  View status: https://{browser_url}/ml/endpoints/{deployment_info.endpoint_name}\n",
       "  Review App: {deployment_info.review_app_url}\"\"\"\n",
       "  return message"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {
       "application/vnd.databricks.v1+cell": {
        "cellMetadata": {
         "byteLimit": 2048000,
         "rowLimit": 10000
        },
        "inputWidgets": {},
        "nuid": "7cdfa543-71b9-41c3-93bf-dbcd9409ed44",
        "showTitle": false,
        "tableResultSettingsMap": {},
        "title": ""
       }
      },
      "source": [
       "### \uD83D\uDD10 Configure Environment Variables\n",
       "\n",
       "Set all required environment variables for the deployed agent to function properly."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
       "application/vnd.databricks.v1+cell": {
        "cellMetadata": {
         "byteLimit": 2048000,
         "rowLimit": 10000
        },
        "inputWidgets": {},
        "nuid": "f94aead5-e0fa-41f1-9f28-c3007217f601",
        "showTitle": false,
        "tableResultSettingsMap": {},
        "title": ""
       }
      },
      "outputs": [],
      "source": [
       "envvars = {\n",
       "    \"ENDPOINT_NAME\" : ENDPOINT_NAME,\n",
       "    \"LAKEBASE_INSTANCE\" : LAKEBASE_INSTANCE,\n",
       "    \"LAKEBASE_USER\" : DATABRICKS_CLIENT_ID,\n",
       "    \"DATABRICKS_CLIENT_ID\" : DATABRICKS_CLIENT_ID,\n",
       "    \"DATABRICKS_CLIENT_SECRET\" : DATABRICKS_CLIENT_SECRET,\n",
       "    \"DATABRICKS_HOST\" : f\"http://{WORKSPACE_URL}\",\n",
       "    \"UC_FUNCTIONS\" : f\"{CATALOG_NAME}.{SCHEMA_NAME}.get_top_usage\",\n",
       "}"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
       "application/vnd.databricks.v1+cell": {
        "cellMetadata": {
         "byteLimit": 2048000,
         "rowLimit": 10000
        },
        "inputWidgets": {},
        "nuid": "39e75662-8951-429c-934f-c53d86b599d1",
        "showTitle": false,
        "tableResultSettingsMap": {},
        "title": ""
       }
      },
      "outputs": [
       {
        "output_type": "display_data",
        "data": {
         "application/vnd.jupyter.widget-view+json": {
          "model_id": "76a84dc6393c48dd8ee1ab8cef8b921e",
          "version_major": 2,
          "version_minor": 0
         },
         "text/plain": [
          "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
         ]
        },
        "metadata": {},
        "output_type": "display_data"
       },
       {
        "output_type": "stream",
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "\n    Deployment of marcin_databricks_demos.sql_workshop.human-interruption-agent version 9 initiated.  This can take up to 15 minutes and the Review App & Query Endpoint will not work until this deployment finishes.\n\n    View status: https://adb-2482403303441070.10.azuredatabricks.net/ml/endpoints/agents_marcin_databricks_demos-sql_workshop-human-interruption\n    Review App: https://adb-2482403303441070.10.azuredatabricks.net/ml/review-v2/0633ac30f9554b02b367cad177dda356/chat\n\nYou can refer back to the links above from the endpoint detail page at https://adb-2482403303441070.10.azuredatabricks.net/ml/endpoints/agents_marcin_databricks_demos-sql_workshop-human-interruption.\nDeployment of marcin_databricks_demos.sql_workshop.human-interruption-agent version 9 initiated.  This can take up to 15 minutes and the Review App & REST API will not work until this deployment finishes. \n\n  View status: https://adb-2482403303441070.10.azuredatabricks.net/ml/endpoints/agents_marcin_databricks_demos-sql_workshop-human-interruption\n  Review App: https://adb-2482403303441070.10.azuredatabricks.net/ml/review-v2/0633ac30f9554b02b367cad177dda356/chat\n"
        ]
       }
      ],
      "source": [
       "from databricks import agents\n",
       "# Deploy to enable the Review APP and create an API endpoint\n",
       "# Note: scaling down to zero will provide unexpected behavior for the chat app. Set it to false for a prod-ready application.\n",
       "deployment_info = agents.deploy(uc_model_fqn, model_version=uc_registered_model_info.version, scale_to_zero=True,\n",
       "    resources=resources,\n",
       "    #@TODO: implement secrets\n",
       "    #environment_vars={\"DATABRICKS_HOST\":\"https://e2-demo-field-eng.cloud.databricks.com\", \"DATABRICKS_TOKEN\":\"{{secrets/marcin_jimenez/databricks_token}}\"}\n",
       "    environment_vars=envvars,\n",
       ")\n",
       "\n",
       "# instructions_to_reviewer = f\"\"\"## Instructions for Testing the Databricks Documentation Assistant chatbot\n",
       "\n",
       "# Your inputs are invaluable for the development team. By providing detailed feedback and corrections, you help us fix issues and improve the overall quality of the application. We rely on your expertise to identify any gaps or areas needing enhancement.\"\"\"\n",
       "\n",
       "# # Add the user-facing instructions to the Review App\n",
       "# agents.set_review_instructions(uc_model_fqn, instructions_to_reviewer)\n",
       "\n",
       "print(parse_deployment_info(deployment_info))"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {
       "application/vnd.databricks.v1+cell": {
        "cellMetadata": {
         "byteLimit": 2048000,
         "rowLimit": 10000
        },
        "inputWidgets": {},
        "nuid": "85410003-0a03-480d-82c9-393aa0d391b6",
        "showTitle": false,
        "tableResultSettingsMap": {},
        "title": ""
       }
      },
      "source": [
       "## ✨ Test Production Deployment\n",
       "\n",
       "Verify the deployed endpoint is working correctly by making a test prediction."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
       "application/vnd.databricks.v1+cell": {
        "cellMetadata": {
         "byteLimit": 2048000,
         "rowLimit": 10000
        },
        "inputWidgets": {},
        "nuid": "90429468-946a-46ea-a9c3-f1389ff7b7ff",
        "showTitle": false,
        "tableResultSettingsMap": {},
        "title": ""
       }
      },
      "outputs": [
       {
        "output_type": "stream",
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "I have access to a specific tool that allows me to retrieve data about usage patterns:\n\n- `marcin_databricks_demos__sql_workshop__get_top_usage`: This function returns top usage data for a specified date. It has one optional parameter called \"target_date\" which can be provided as a date string.\n\nThis tool appears to be related to a Databricks SQL workshop and can help analyze usage patterns for a particular date. If you'd like me to use this tool to retrieve data, you can specify a date, and I can execute the query for you after receiving your approval.\n\nIs there a specific date for which you'd like to see top usage data?\n"
        ]
       }
      ],
      "source": [
       "from mlflow.deployments import get_deploy_client\n",
       "\n",
       "deploy_client = get_deploy_client()\n",
       "\n",
       "# Query your deployed agent\n",
       "response = deploy_client.predict(\n",
       "    endpoint=deployment_info.endpoint_name,\n",
       "    inputs=input_example\n",
       ")\n",
       "\n",
       "print(response.messages[-1]['content'])"
      ]
     }
    ],
    "metadata": {
     "application/vnd.databricks.v1+notebook": {
      "computePreferences": {
       "hardware": {
        "accelerator": null,
        "gpuPoolId": null,
        "memory": null
       }
      },
      "dashboards": [],
      "environmentMetadata": null,
      "inputWidgetPreferences": null,
      "language": "python",
      "notebookMetadata": {
       "mostRecentlyExecutedCommandWithImplicitDF": {
        "commandId": -1,
        "dataframes": [
         "_sqldf"
        ]
       },
       "pythonIndentUnit": 4
      },
      "notebookName": "e2e-human-interruption-agent",
      "widgets": {
       "catalog_name": {
        "currentValue": "marcin_databricks_demos",
        "nuid": "21e000c1-5e0c-4af7-ae6d-1c6531bdced5",
        "typedWidgetInfo": {
         "autoCreated": false,
         "defaultValue": "_databricks_demos",
         "label": "Databricks Catalog",
         "name": "catalog_name",
         "options": {
          "widgetDisplayType": "Text",
          "validationRegex": null
         },
         "parameterDataType": "String"
        },
        "widgetInfo": {
         "widgetType": "text",
         "defaultValue": "_databricks_demos",
         "label": "Databricks Catalog",
         "name": "catalog_name",
         "options": {
          "widgetType": "text",
          "autoCreated": null,
          "validationRegex": null
         }
        }
       },
       "db_client_id": {
        "currentValue": "920e73f0-df21-47d9-9acf-fe926acfd4f8",
        "nuid": "46f9862b-b811-43b4-8d9c-f9cd19f417db",
        "typedWidgetInfo": {
         "autoCreated": false,
         "defaultValue": "<uuid>",
         "label": "Databricks Client ID",
         "name": "db_client_id",
         "options": {
          "widgetDisplayType": "Text",
          "validationRegex": null
         },
         "parameterDataType": "String"
        },
        "widgetInfo": {
         "widgetType": "text",
         "defaultValue": "<uuid>",
         "label": "Databricks Client ID",
         "name": "db_client_id",
         "options": {
          "widgetType": "text",
          "autoCreated": null,
          "validationRegex": null
         }
        }
       },
       "db_client_secret": {
        "currentValue": "",
        "nuid": "67091dd8-71ff-4d7e-bd0c-0e4f8068cdff",
        "typedWidgetInfo": {
         "autoCreated": false,
         "defaultValue": "Secret",
         "label": "Databricks Client Secret",
         "name": "db_client_secret",
         "options": {
          "widgetDisplayType": "Text",
          "validationRegex": null
         },
         "parameterDataType": "String"
        },
        "widgetInfo": {
         "widgetType": "text",
         "defaultValue": "Secret",
         "label": "Databricks Client Secret",
         "name": "db_client_secret",
         "options": {
          "widgetType": "text",
          "autoCreated": null,
          "validationRegex": null
         }
        }
       },
       "endpoint_name": {
        "currentValue": "databricks-claude-3-7-sonnet",
        "nuid": "c363f014-e430-4876-a339-e3d6dc08730d",
        "typedWidgetInfo": {
         "autoCreated": false,
         "defaultValue": "databricks-claude-3-7-sonnet",
         "label": "Model Serving Endpoint",
         "name": "endpoint_name",
         "options": {
          "widgetDisplayType": "Text",
          "validationRegex": null
         },
         "parameterDataType": "String"
        },
        "widgetInfo": {
         "widgetType": "text",
         "defaultValue": "databricks-claude-3-7-sonnet",
         "label": "Model Serving Endpoint",
         "name": "endpoint_name",
         "options": {
          "widgetType": "text",
          "autoCreated": null,
          "validationRegex": null
         }
        }
       },
       "lakebase_instance": {
        "currentValue": "agent-human-interaction",
        "nuid": "3823affd-a33a-4f7a-8746-5444a6bd53ee",
        "typedWidgetInfo": {
         "autoCreated": false,
         "defaultValue": "agent-human-interaction",
         "label": "Lakebase Instance Name",
         "name": "lakebase_instance",
         "options": {
          "widgetDisplayType": "Text",
          "validationRegex": null
         },
         "parameterDataType": "String"
        },
        "widgetInfo": {
         "widgetType": "text",
         "defaultValue": "agent-human-interaction",
         "label": "Lakebase Instance Name",
         "name": "lakebase_instance",
         "options": {
          "widgetType": "text",
          "autoCreated": null,
          "validationRegex": null
         }
        }
       },
       "schema_name": {
        "currentValue": "sql_workshop",
        "nuid": "d3393eec-ed9d-4ab1-a614-3533d551a097",
        "typedWidgetInfo": {
         "autoCreated": false,
         "defaultValue": "sql_workshop",
         "label": "Schema name",
         "name": "schema_name",
         "options": {
          "widgetDisplayType": "Text",
          "validationRegex": null
         },
         "parameterDataType": "String"
        },
        "widgetInfo": {
         "widgetType": "text",
         "defaultValue": "sql_workshop",
         "label": "Schema name",
         "name": "schema_name",
         "options": {
          "widgetType": "text",
          "autoCreated": null,
          "validationRegex": null
         }
        }
       }
      }
     },
     "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "name": "python"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 0
   }